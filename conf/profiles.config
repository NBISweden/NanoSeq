
/*
----------------------------------------------------------------------------------------

Profiles

- Includes stripped down set of container/software env profiles

- Assumes development on a laptop, thus the default resource profile is similar to nf-core test, rather than nf-core base (which assumes a HPC environment)

- Includes HPC base profile for unconfigured HPC environments, based on nf-core base

----------------------------------------------------------------------------------------
*/

profiles {

	// Utility profiles

	debug {
		dumpHashes              = true
		process.beforeScript    = 'echo $HOSTNAME'
		cleanup                 = false
		nextflow.enable.configProcessNamesValidation = true
	}

	// Container/software env profiles

	apptainer {
		apptainer.enabled       = true
		apptainer.autoMounts    = true
		apptainer.cacheDir      = "work/apptainer"
		apptainer.runOptions    = '--bind $HOME'
		conda.enabled           = false
		docker.enabled          = false
		singularity.enabled     = false
		podman.enabled          = false
		shifter.enabled         = false
		charliecloud.enabled    = false
	}

	singularity {
		singularity.enabled     = true
		singularity.autoMounts  = true
		singularity.cacheDir    = "work/singularity"
		conda.enabled           = false
		docker.enabled          = false
		podman.enabled          = false
		shifter.enabled         = false
		charliecloud.enabled    = false
		apptainer.enabled       = false
	}

	wave {
		apptainer.ociAutoPull   = true
		singularity.ociAutoPull = true
		wave.enabled            = true
		wave.freeze             = true
		wave.strategy           = 'conda,container'
	}

	conda {
		conda.enabled           = true
		docker.enabled          = false
		singularity.enabled     = false
		podman.enabled          = false
		shifter.enabled         = false
		charliecloud.enabled    = false
		conda.channels          = ['conda-forge', 'bioconda']
		apptainer.enabled       = false
	}

	// Resource profiles for development

	standard {
		executor.name           = 'local'
		executor.cpus           = 8
		executor.memory         = 16.GB
		process {
			resourceLimits = [
				cpus: 8,
				memory: '16.GB',
				time: '1.h'
			]
			withLabel: process_single {
				cpus = 1
				memory = 1.GB
			}
			withLabel: process_low {
				cpus = 2
				memory = 2.GB
			}
			withLabel: process_medium {
				cpus = 3
				memory = 4.GB
			}
			withLabel: process_high {
				cpus = 5
				memory = 8.GB
			}
		}
	}

	gitpod {
		executor.name           = 'local'
		executor.cpus           = 4
		executor.memory         = 8.GB
		process {
			resourceLimits = [
				memory: 8.GB,
				cpus  : 4,
				time  : 1.h
			]
		}
	}

	// Resource profiles for HPC environments

	baseHPC {
		// nf-core base
		process {
			cpus   = { 1      * task.attempt }
			memory = { 6.GB   * task.attempt }
			time   = { 4.h    * task.attempt }
			errorStrategy = { task.exitStatus in ((130..145) + 104) ? 'retry' : 'finish' }
			maxRetries    = 1
			maxErrors     = '-1'
			withLabel:process_single {
				cpus   = { 1                   }
				memory = { 6.GB * task.attempt }
				time   = { 4.h  * task.attempt }
			}
			withLabel:process_low {
				cpus   = { 2     * task.attempt }
				memory = { 12.GB * task.attempt }
				time   = { 4.h   * task.attempt }
			}
			withLabel:process_medium {
				cpus   = { 6     * task.attempt }
				memory = { 36.GB * task.attempt }
				time   = { 8.h   * task.attempt }
			}
			withLabel:process_high {
				cpus   = { 12    * task.attempt }
				memory = { 72.GB * task.attempt }
				time   = { 16.h  * task.attempt }
			}
			withLabel:process_long {
				time   = { 20.h  * task.attempt }
			}
			withLabel:process_high_memory {
				memory = { 200.GB * task.attempt }
			}
			withLabel:error_ignore {
				errorStrategy = 'ignore'
			}
			withLabel:error_retry {
				errorStrategy = 'retry'
				maxRetries    = 2
			}
		}
	}

	dardelSlurm {
		containerOptions = "-B /cfs/klemming/"
		apptainer {
			envWhitelist = 'PDC_TMP'
		}
		executor {
			name = 'slurm'
			account = params.account
			jobName = { "${task.name.tokenize(':')[-1].replaceAll(/[^a-zA-Z0-9]/, '_')}_${task.hash.take(10)}".replaceAll(/_+/, '_') }
			queueSize = 1000
		}
		process {
			errorStrategy = { task.exitStatus in ((130..145) + 104) ? 'retry' : 'terminate' }
			maxRetries = 2
			scratch = '$PDC_TMP'
			withLabel: process_single {
				queue = 'shared'
				cpus = 1
				time = { 5.h * task.attempt }
			}
			withLabel: process_low {
				queue = 'shared'
				cpus = { 48 * task.attempt }
				memory = { 39.GB * task.attempt }
				time = { 5.h * task.attempt }
			}
			withLabel: process_medium {
				queue = 'main'
				clusterOptions = '--nodes=1'
				cpus = 64
				memory = 230.GB
				time = { 12.h * task.attempt }
			}
			withLabel: process_high {
				queue = 'memory'
				clusterOptions = '--nodes=1'
				cpus = 64
				memory = 460.GB
				time = { 12.h * task.attempt }
			}
		}
	}

	rackhamSlurm {
		apptainer {
			envWhitelist = 'SNIC_TMP'
		}
		executor {
			name = 'slurm'
			account = params.account
			jobName = { "${task.name.tokenize(':')[-1].replaceAll(/[^a-zA-Z0-9]/, '_')}_${task.hash.take(10)}".replaceAll(/_+/, '_') }
			queueSize = 1000
		}
		process {
			errorStrategy = { task.exitStatus in ((130..145) + 104) ? 'retry' : 'terminate' }
			maxRetries = 1
			scratch = '$SNIC_TMP'
			withLabel: process_single {
				queue = 'core'
				cpus = 1
				memory = 8.GB
				time = { 12.h * task.attempt }
			}
			withLabel: process_low {
				queue = 'core'
				cpus = { 10 * task.attempt }
				memory = { 60.GB * task.attempt }
				time = { 24.h * task.attempt }
			}
			withLabel: process_medium {
				queue = 'node'
				clusterOptions = '--nodes=1 -C mem256GB'
				cpus = 20
				memory = 230.GB
				time = { 36.h * task.attempt }
			}
			withLabel: process_high {
				queue = 'node'
				clusterOptions = '--nodes=1 -C mem1TB'
				cpus = 20
				memory = 920.GB
				time = { 36.h * task.attempt }
			}
		}
	}

	// Original Sanger lsf_singularity profile, unchanged (note some redundancy with container profiles)

	lsf_singularity {
		singularity.enabled = true
		singularity.autoMounts = true
		singularity.cacheDir = "$PWD"
		singularity.envWhitelist = "REF_PATH,REF_CACHE"
		process.executor = 'lsf'
		process.queue = 'normal'
		executor.perJobMemLimit = true
		executor.queueSize = 200
		process.cache = 'lenient' //necesary for lustre
		process.errorStrategy = 'retry' //relaunch jobs upon failure
		process.maxRetries = 2
		process.beforeScript = 'module load singularity/3.9.0'
		env.REF_PATH = "/path/to/cram_cache/%2s/%2s/%s" //required for CRAM
	}

}
